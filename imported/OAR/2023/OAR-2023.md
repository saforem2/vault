# OAR 2023 

## Section 4. Innovation

### ALCF Response

Listed below are the innovations and best practices carried out at ALCF during CY 2023.

ALCF innovations and best practices have helped to prepare for future systems, have enabled more efficient operations, and have strengthened collaboration and engagement, both across ASCR facilities and beyond.

### 4.1 Science Innovation & Best Practices

The ALCF Science teams have undertaken several projects to improve and maintain the scientific applications offered to users of the facility.

_Filippo Simini_

**Challenge**: Graph Neural Networks (GNNs), which learn representations of non-euclidean data in the form of graphs, are rapidly rising in popularity and are used in several computationally demanding scientific applications.

As deep GNN models become more prevalent in practical HPC applications, their performance during inference becomes increasingly critical.

GNNs have been shown to suffer from hard memory and computational bottlenecks on traditional hardware platforms (i.e. GPUs) due in part to their reliance on non-contiguous data structures.

While dataflow architectures used by emerging hardware accelerators provide a potential solution to alleviate these issues, end-to-end GNN models are generally not yet or only partially supported by these platforms.

**Approach**: We are collaborating with three hardware accelerator vendors to test and benchmark GNN models on their AI platforms.

First, we select a handful of representative GNN models, including "GATv2" and "SchNet", that are both state-of-the-art as well as represent a diversity of downstream tasks.

We profile these models to identify operators, including kernels such as "gather" and "index_select", that are the most relevant and computationally expensive for these architectures.

We then analyze the performance of these lower level operators and collect microbenchmark indicators of their performance on the different AI platforms and on traditional GPUs. 

Finally, we profile the end-to-end GNN models that are currently available on the various AI platforms in order to compare their performance against that of traditional GPUs and to identify computational bottlenecks and opportunities to further optimize GNN model inference on these novel AI accelerators.

Impact/status: Our collaboration with AI accelerator vendors contributes to prioritize the support of GNN-relevant operators as well as of end-to-end GNN models on these platforms and provides hints about the performance of GNN models on dataflow architectures.



_Sam Foreman_


Challenge: Coordinate efforts for [DeepSpeed4Science](https://deepspeed4science.ai) collaboration focused on scaling the context window (sequence length) for training genome scale language models with the GenSLM team. 

Approach: This effort involved a major update and rebase of the [microsoft/Megatron-DeepSpeed](https://github.com/microsoft/Megatron-DeepSpeed) codebase used for training large language models. Through these improved parallelism techniques we are able to train with significantly longer sequence lengths (from 41k to 512k for 25B model), allowing for greater contextual information in important downstream scientific tasks.


Impact / status: This work was part of the initial DeepSpeed4Science release from the Microsoft DeepSpeed team and the result of a many month collaborative effort with  the Microsoft DeepSpeed team. This will have a large impact on distributed training performance, particularly for large models using multiple degrees of parallelism going forward on ALCF systems. These efforts resulted in a publication [DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery through Sophisticated AI System Technologies](https://openreview.net/forum?id=kQyP5u5ccw) at the [AI for Scientific Discovery: From Theory to Practice](https://ai4sciencecommunity.github.io/neurips23.html) workshop at NeurIPS'23 and a [blog post](https://deepspeed4science.ai/2023/09/18/model-showcase-genslms/) from Microsoft.

has resulted in an ongoing collaboration and and that will have a significant improvement on training performance for large language models for scientific applications. 

: Scale up the `sequence_length` used during training for LLMs.

